# -*- coding: utf-8 -*-
"""Pandas MultiIndexing & Groupby - Skeleton.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MLz9aOWKk5ySoiVUcHQIG44vCgfLxU6M

# 1. IMPORT AND EXPLORE DATASET
"""

import pandas as pd

# Import dataset using Pandas
# Link to Dataset: https://www.kaggle.com/carrie1/ecommerce-data
# Data contains transactions details between 01/12/2010 and 09/12/2011 for a UK-based non-store online retail.
# The company specializes in selling unique gifts

sales_df = pd.read_csv('ecommerce_sales.csv', encoding = 'unicode_escape')
sales_df

# Let's view the types of data
# Note that InvoiceDate is in object format, we will need to convert it into Datetime format

sales_df.info()

# Convert Invoice date to datetime format

sales_df['InvoiceDate'] = pd.to_datetime(sales_df['InvoiceDate'])

# Check datatype again to confirm!
sales_df.info()

# Check the number of Null values in the data
sales_df.isnull().sum()

"""**MINI CHALLENGE #1:**
- **How many unique countries are present in the dataset? List all countries**
"""

sales_df['Country']

unique_country = sales_df['Country'].value_counts()

unique_country

unique_country.unique()

"""The actual solutions is"""

sales_df['Country'].unique()

sales_df['Country'].nunique()

"""# 2. GROUPBY"""

sales_df

# A groupby operation involves some combination of splitting the object, applying a function, and combining the results. 
# This can be used to group large amounts of data and compute operations on these groups.
# Link: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html

sales_df.groupby('Country')['UnitPrice'].mean()

sales_df.groupby('Country')['UnitPrice'].min()

sales_df.groupby('Country')['UnitPrice'].max()

sales_df.groupby('InvoiceDate')['UnitPrice'].mean()

sales_df.groupby(['InvoiceDate', 'Country'])['UnitPrice'].mean()



"""**MINI CHALLENGE #2:**
- **What is the average, maximum and minimum prices on 2010-12-01 08:34:00**
"""

sales_df.groupby('InvoiceDate')['UnitPrice'].mean()

sales_df.groupby('InvoiceDate')['UnitPrice'].min()

sales_df.groupby('InvoiceDate')['UnitPrice'].max()

"""# 3. CREATE MULTI-INDEX DATAFRAME"""

sales_df = pd.read_csv('ecommerce_sales.csv', encoding = 'unicode_escape')
sales_df

# You can select any column to be the index for the DataFrame
# Use one column only as follows:

sales_df.set_index(keys = ['InvoiceDate'], inplace = True)
sales_df

# Let's see how many unique countries are present in the dataframe

sales_df['Country'].unique()

# Alternatively, We can have multiple keys (indexes) using Pandas Multi-indexing
# Take the columns with the least number of unique values and use it for the outermost index

sales_df = pd.read_csv('ecommerce_sales.csv', encoding = 'unicode_escape')
sales_df.set_index(keys = ['Country', 'InvoiceDate'], inplace = True)

# Let's import the dataset again using Pandas
sales_df

# Sort countries to start with alphabetical order

sales_df.sort_index(inplace = True)
sales_df

# Now you need more than one index to access any element

sales_df.index

sales_df.index.names

# Multiindex objects
type(sales_df.index)

# It gives out the datetime and the country as well

sales_df.index[0]

"""**MINI CHALLENGE #3:**
- **Sort the DataFrame in a descending order (countries and dates)**
"""

sales_df = pd.read_csv('ecommerce_sales.csv', encoding = 'unicode_escape')
sales_df

sales_df.set_index(keys = ['Country', 'InvoiceDate'], inplace = True)
sales_df

sales_df.sort_index(ascending = False, inplace = True)
sales_df

"""# 4. MULTI-INDEXING OPERATIONS - PART #1"""

sales_df = pd.read_csv('ecommerce_sales.csv', encoding = 'unicode_escape')
sales_df

sales_df.set_index(keys = ['Country', 'InvoiceDate'], inplace = True)
sales_df

sales_df.index.get_level_values(0)

sales_df.index.get_level_values(1)

sales_df.index.get_level_values('Country')

sales_df.index.get_level_values('InvoiceDate')

# You can change the names of the DataFrame by invoking the set_names method

sales_df.index.set_names(names = ['TransactionLocation', 'TransactionDate'], inplace = True)

sales_df

"""**MINI CHALLENGE #4:**
- **Use InvoiceDate and Country in order as the multi-index**
- **Change the name of both indexes to "Date" and "location"**
"""

sales_df = pd.read_csv('ecommerce_sales.csv', encoding = 'unicode_escape')
sales_df

sales_df.set_index(keys = ['InvoiceDate', 'Country'], inplace = True)
sales_df

sales_df.index.set_names(names = ['Date', 'Location'], inplace = True)
sales_df

"""# 5. MULTI-INDEXING OPERATIONS - PART #2"""

sales_df = pd.read_csv('ecommerce_sales.csv', encoding = 'unicode_escape')
sales_df
# Sort countries to start with alphabetical order
sales_df.set_index(keys = ['Country', 'InvoiceDate'], inplace = True)
sales_df.sort_index()

# you can use a multi-index reference to access specific elements 
# Alternatively, you can use a column name instead 

sales_df.loc['Australia', '1/11/2011 9:47']

# feed index as a tuple (important to avoid confusion)
# first argument references rows and the second argument references a column

sales_df.loc[('Australia', '1/11/2011 9:47'), 'UnitPrice']

sales_df.sort_index(inplace = True)
sales_df

# no issues with numeric indexing, you can use one index so no tuples are required

sales_df.iloc[0]

# no issues with numeric indexing

sales_df.iloc[0, 0]

# You can use transpose to Transpose indexes and columns
# reflect the DataFrame over its main diagonal by writing rows as columns and vice-versa. 

sales_df = sales_df.transpose()
sales_df.head(10)

sales_df.loc['UnitPrice', ('Australia', '1/11/2011 9:47')]

sales_df.loc['UnitPrice', ('Australia', '1/11/2011 9:47'):('Belgium','1/11/2011 9:47')]



# Let's import the dataset again using Pandas

sales_df = pd.read_csv('ecommerce_sales.csv', encoding = 'unicode_escape')
sales_df.set_index(keys = ['Country', 'InvoiceDate'], inplace = True)
sales_df

# You can perform swaplevel as follows:

sales_df = sales_df.swaplevel()
sales_df

# Perform swaplevel again:

sales_df = sales_df.swaplevel()
sales_df

"""**MINI CHALLENGE #5:**
- **Calculate the average unit price for transactions occured in "United Kingdom" at "12/1/2010 8:26"**
"""

sales_df

sales_df = sales_df.transpose()
sales_df.head()

sales_df.loc['UnitPrice', ('United Kingdom', '12/1/2010 8:26')].mean()