# -*- coding: utf-8 -*-
"""Copy of Pandas DataFrames Fundamentals - Skeleton.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13aBiyUd9intb8-46RCi_kYWFYjE2SChd

# 1. DEFINE A PANDAS DATAFRAME
"""

import pandas as pd

# Let's define a two-dimensional Pandas DataFrame
# Note that you can create a pandas dataframe from a python dictionary

bank_info_df = pd.DataFrame({'Bank Client ID': [111, 122, 133, 144],
           'Bank Client Name': ['Jonathan Herd', 'Steve Buyers', 'Shrishti Tiwari', 'Francis Morris'],
           'Net Worth': [1500, 3400, 10000, 6000],
           'Years With Bank': [2, 4, 9, 6]})

bank_info_df

# Let's obtain the data type 

type(bank_info_df)

# you can only view the first couple of rows using .head()

bank_info_df.head(2)

# you can only view the last couple of rows using .tail()

bank_info_df.tail(2)

# You can obtain the shape of the DataFrame (#rows, #columns)

bank_info_df.shape

# Obtain DataFrame information 

bank_info_df.info()

"""**MINI CHALLENGE #1:**
- **A porfolio contains a collection of securities such as stocks, bonds and ETFs. Define a dataframe named 'portfolio_df' that holds 3 different stock ticker symbols, number of shares, and price per share (feel free to choose any stocks)**
- **Calculate the total value of the porfolio including all stocks**
"""

my_collection = pd.DataFrame({'Stock_Ticker_Symbol': ['AMZN', 'MSFT', 'AAPL'],
                              'Number Of Shares': [2, 3, 6],
                              'Price Per Shares': [230, 300, 450]})

total_collections = my_collection['Number Of Shares']*my_collection['Price Per Shares']
total_collections

total_collections.sum()

"""# 2. INPUTS (READ CSV AND HTML DATA)"""

# Pandas is used to read a csv file and store data in a DataFrame
bank_df = pd.read_csv('bank_client_information.csv')

bank_df

# Read tabular data using read_html

house_price_df = pd.read_html('https://www.livingin-canada.com/house-prices-canada.html')

house_price_df[0]

house_price_df[1]

"""**MINI CHALLENGE #2:**
- **Write a code that uses Pandas to read tabular US retirement data**
- **You can use data from here: https://www.ssa.gov/oact/progdata/nra.html** 
"""

US_retirement_df = pd.read_html('https://www.ssa.gov/oact/progdata/nra.html')
US_retirement_df[0]

"""# 3. OUTPUTS (WRITE DATAFRAME INTO CSV)"""

# Let's define a two-dimensional Pandas DataFrame
# Note that you can create a pandas dataframe from a python dictionary

bank_df = pd.read_csv('/content/bank_client_information.csv')
bank_df

bank_df.to_csv('Sample_Bank_Info.csv', index = True)

"""**MINI CHALLENGE #3:**
- **Use set index = False and rerun the cell. Comment on the output CSV.**
- **Try to leverage the attribute compression and rerun the cell**
"""

bank_df.to_csv('Sample_bank_info2.csv', index = False)

bank_df.to_csv('Sample_bank_info2.csv.gz', index = False, compression = 'gzip')

"""# 4. SETTING/RESETTING INDEX"""

# Pandas is used to read a csv file and store data in a DataFrame
# Note that a numeric index is being set by default

bank_df = pd.read_csv('bank_client_information.csv')
bank_df

# You can assign a specific column to be the index as follows

bank_df.set_index('First Name', inplace = True)
bank_df

# You can go back and use numeric index using reset_index

bank_df.reset_index(inplace = True)
bank_df

# Alternatively, you can set the index name when you read the csv file as follows

bank_df = pd.read_csv('bank_client_information.csv', index_col = 'Years with Bank')
bank_df

"""**MINI CHALLENGE #4:**
- **Load the bank_client_information.csv and then set the "Last Name" column as the index**
"""

bank_df = pd.read_csv('bank_client_information.csv')
bank_df

bank_df = pd.read_csv('bank_client_information.csv', index_col = 'Last Name')
bank_df

"""# 5. SELECTING COLUMNS FROM A DATAFRAME"""

# Pandas is used to read a csv file and store data in a DataFrame

bank_df = pd.read_csv('bank_client_information.csv')
bank_df

# Return a column from the DataFrame
# Note that the output will be a Pandas Series (you can automatically tell by the lack of formating)

bank_email_df = bank_df['Email']
bank_email_df

# Confirm the datatype of sample
type(bank_email_df)

# Alternatively, you can use the following syntax to do the same
# Note that this method will not work if there are spaces in the column names

bank_df.Email

# Since the column name has spaces, this will be the only way that will work!

bank_df['Net Worth']

# Let's select multiple columns from the DataFrame
# you need to define a list containing all column names that you would like to select
# Note that since we collected more than one column, the output is a DataFrame (Notice the rich formatting)

samples = bank_df[['First Name', 'Net Worth']]
samples

# Note that sample is now a DataFrame and not a Pandas Series (since it has multiple columns)
# You can use type to confirm or you can tell from the rich text formating

type(samples)

# Alternatively, you can define a list first and then use it to select columns
my_samples = ['First Name', 'Net Worth', 'Years with Bank']
selected = bank_df[my_samples]
selected

# In order to access a given row in the dataframe

bank_df[0:3]

"""**MINI CHALLENGE #5:**
- **Select the following columns from the dataFrame Net Worth, Years with Bank, and Postal Code**
"""

bank_samples = ['Net Worth', 'Years with Bank', 'Postal Code']
bank_df[bank_samples]

"""# 6. ADDING/DELETING COLUMNS TO DATAFRAME"""

# Pandas is used to read a csv file and store data in a DataFrame
bank_df = pd.read_csv('bank_client_information.csv')
bank_df

# Let's assume that we want to add a new column to the dataframe
bank_df['Age'] = [25, 34, 27, 23, 29, 30, 33, 23, 38, 36]

bank_df

# You can also insert a new column in a given position 
bank_df.insert(2, column = 'credit Score', value = [680, 750, 330, 420, 890, 560, 450, 620, 745, 820])

bank_df

# Delete a column from a DataFrame

del bank_df['Last Name']

bank_df

# Remove a column from a DataFrame and store it somehwere else using pop

bank_df.pop('Years with Bank')

"""**MINI CHALLENGE #6:**
- **load the bank_client_information.csv file and perform the following: (assume any reasonable values)** 
    - **Add a column indicating whether the client has a mortgage or not**
    - **Add a column indicating the value of mortage in dollars**  
"""

bank_df['Has Mortgage'] = [1, 0, 0, 0, 1, 1, 0, 0, 0, 1]
bank_df['Mortgage Rate'] = [35000, 0, 0, 0, 40000, 38000, 0, 0, 0, 48000]
bank_df

"""# 7. LABEL-BASED ELEMENTS SELECTION FROM A DATAFRAME ".LOC()"""

# Load the csv file and set the last name as the index

bank_df = pd.read_csv('bank_client_information.csv', index_col = 'Last Name')
bank_df

# Sort the dataframe in an alphabetical order

bank_df.sort_index(inplace = True)
bank_df

# loc is used to filter rows and columns
# loc is label-based meaning you need to give a name of the rows (or columns) that you are interested in selecting
# Note that iloc is "integer index-based" meaning you can filter rows/columns by their integer index.
# Note that we obtained a Series because last name "Small" existed only once in the dataframe

bank_df.loc['Patton']

# Note that you got a DataFrame back since Last Name 'Steve' existed more than one in the DataFrame

bank_df.loc['Steve']

# Note that you can select multiple rows using "colon :"
# Note that this is inclusive! meaning that "Ahmed" and "Patton" were selected in the output DataFrame
# Headsup: this will be different if we use integer based index such as iloc()

bank_df.loc['Ahmed':'Patton']

# Select all elements up to and including 'Keller' index

bank_df.loc[:'Keller']

# if you want to select multiple rows, you can pass them as a list as follows
my_list = ['Moran', 'Steve', 'Ismail', 'Mo']
bank_df.loc[my_list]

# You can also randomly select a fraction of the DataFrame
# Setting axis = 0 means rows, setting index = 1 means columns

bank_df.sample(n = 4, axis = 0)

# return a percentage (Ex: 30%) of the rows 

bank_df.sample(frac = 0.3, axis = 0)

"""**MINI CHALLENGE #7:**
- **Load the csv data and use the "first name" column as the index**
- **Randomly select 2 rows from the DataFrame. Rerun the code and ensure that random rows are being selected**
"""

bank_df = pd.read_csv('bank_client_information.csv', index_col = 'First Name')
bank_df

bank_df.sample(n=2, axis=0)

"""# 8. INTEGER INDEX-BASED ELEMENTS SELECTION FROM A DATAFRAME "iLOC()"""

# Load the CSV file with default index

bank_df = pd.read_csv('bank_client_information.csv')
bank_df

# You can access rows with their numeric index using iloc

bank_df.iloc[4]

# You can access multiple rows with their numeric index using iloc and colon :
# Note that using iloc is exclusive, meaning that we did not include the last element (quite confusing I know!)
# We went from index = 2 up until and not including index 5 so index 2,3, and 4 are the one selected

bank_df.iloc[2:6]

# all up until and not including index 4

bank_df.iloc[:4]

# Multiple elements are selected using a list of indexes 

elements = [3, 6, 7, 9]
bank_df.iloc[elements]

# Slicing a piece of the dataframe by selecting which row and column you would like to select

bank_df.iloc[2, 0:3]
bank_df.iloc[5, 2:5]

"""**MINI CHALLENGE #8:**
- **Write a code that selects the last two rows in the DataFrame using two different methods**
"""

bank_df.iloc[-2:]

bank_df.iloc[8:]

"""# 9. BROADCASTING OPERATIONS & SETTING NEW DATAFRAME VALUES"""

# Pandas is used to read a csv file and store data in a DataFrame

bank_df = pd.read_csv('bank_client_information.csv')
bank_df

# Let's assume that we want to update the networth of all our customers by $1000

bank_df['Net Worth'] = bank_df['Net Worth'] + 1000
bank_df

bank_df['Net Worth'] = bank_df['Net Worth'].add(1000)
bank_df

# Alternatively, you can add or subtract as follows

bank_df['Net Worth'] = bank_df['Net Worth'].sub(1000)
bank_df

# Let's convert from USD to CAD using the exchange rate 1 USD = 1.3 CAD 

bank_df['Net Worth [CAD]'] = bank_df['Net Worth'].mul(1.3)
bank_df

# Decided to update the email address of a given customer

bank_df.iloc[4, 2] = 'noor.kate@gmail.com'

bank_df

# Let's assume we want to update the networth of two clients

bank_df.iloc[[3,4], [4]] = [14074.00, 8000.00]

bank_df

"""**MINI CHALLENGE #9:**
- **Let's assume that all clients in the bank has been investing their assets in a broad S&P500 ETF. The market has been performing really well and clients networth has increased by 12% annualy. Calculate the sum of all client's networth.** 
"""

bank_df = pd.read_csv('bank_client_information.csv')
bank_df

bank_df['Net Worth New'] = bank_df['Net Worth'].mul(1.12)
bank_df

bank_df['Net Worth New'].sum()

print('Therefore the total clients networth = ${}'.format(bank_df['Net Worth New'].sum()))

"""# 10. SORTING AND ORDERING"""

# Let's read a CSV file using Pandas as follows

bank_df = pd.read_csv('bank_client_information.csv')
bank_df

# You can sort the values in the dataframe according to number of years with bank

bank_df.sort_values(by = 'Years with Bank')

# Note that nothing changed in memory! you have to make sure that inplace is set to True
bank_df

# Set inplace = True to ensure that change has taken place in memory 

bank_df.sort_values(by = 'Years with Bank', inplace = True)

# Note that now the change (ordering) took place 

bank_df

# You can sort the values in a descending order as follows

bank_df.sort_values(by = 'Years with Bank', inplace = True, ascending = False)
bank_df

# You can sort the dataframe with index instead of values as follows

bank_df.sort_index(inplace = True)
bank_df

bank_df['Rank'] = bank_df['Net Worth'].rank(ascending = True).astype('int')

bank_df

"""**MINI CHALLENGE #10:**
- **Sort customers by networth instead of years with bank. Make sure to update values in-memory.**
"""

bank_df.sort_values(by = 'Net Worth', inplace = True)

bank_df

"""# 11. PANDAS WITH FUNCTIONS"""

# Let's read a CSV file using Pandas as follows
bank_df = pd.read_csv('bank_client_information.csv')
bank_df

# Define a function that increases all clients networth by a fixed value of 10% (for simplicity sake) 

def networth_update(value):
  return value * 1.1

# You can apply a function to the DataFrame 

bank_df['Net Worth'] = bank_df['Net Worth'].apply(networth_update)
bank_df

bank_df['Name Length'] = bank_df['First Name'].apply(len)

bank_df

"""**MINI CHALLENGE #11:**
- **Define a function that doubles an argument and adds $100**
- **Apply the function to the Net Worth Column in the DataFrame**
- **Calculate the updated total networth of all clients combined**
"""

def updated_networth(balance):
  return balance * 2 + 100

bank_df['Net Worth'] = bank_df['Net Worth'].apply(updated_networth)
bank_df

total_networth = bank_df['Net Worth'].sum()
total_networth

"""# 12. PANDAS OPERATIONS/FILTERING"""

# Let's read a CSV file using Pandas as follows
bank_df = pd.read_csv('bank_client_information.csv')
bank_df

# Pick certain rows that satisfy a certain criteria 

loyal_df = bank_df[ (bank_df['Years with Bank'] >= 10) ]
loyal_df

# Pick certain rows that satisfy 2 or more critirea

mask1 = bank_df['Years with Bank'] >= 10
mask2 = bank_df['Net Worth'] >= 50000

filter = bank_df[mask1 & mask2]
filter

# Pick certain rows that satisfy a certain criteria 

filtered_value = bank_df[(bank_df['First Name'] == 'Heba')]
filtered_value

collected_value = bank_df[ (bank_df['Last Name'].isin(['Steve', 'Mo'])) ]
collected_value

# values that fall between a given range

range_value = bank_df[ (bank_df['Net Worth'].between(10000, 100000)) ]
range_value

# Delete duplicated rows
bank_df['Last Name'].duplicated(keep = False)

# add a tilde symbol ~

duplicate_value = bank_df[~ bank_df['Last Name'].duplicated(keep = False)]
duplicate_value

# Let's read a CSV file using Pandas as follows

bank_df= pd.read_csv('bank_client_information.csv')
bank_df

# Drop duplicates

bank_df.drop_duplicates(subset = ['Last Name'], inplace = True)

bank_df

from numpy import where
# We can also filter the Dataframe using the where method as follows
# Note that all rows that don't satisfy this critirea are set to NaN

bank_df = pd.read_csv('bank_client_information.csv')
filter = bank_df['Years with Bank'] >= 10

bank_df.where(filter)

"""**MINI CHALLENGE #12:**
- **Using "bank_client_df" DataFrame, leverage pandas operations to only select high networth individuals with minimum $15000** 
- **What is the combined networth for all customers with 15000+ networth?**
"""

high_value = bank_df[ (bank_df['Net Worth'] >= 15000) ]
high_value

total_high_value = high_value['Net Worth'].sum()
total_high_value

print('The total networth above 15000 = $ {}'.format(total_high_value))

"""# 13. FEATURE ENGINEERING AND DEALING WITH MISSING DATASET"""

# Let's read a CSV file using Pandas as follows

employee_df = pd.read_csv('Human_Resources.csv')
employee_df

# first, let's locate rows that have Null values
employee_df.isnull()

# first, let's locate rows that have Null values

employee_df.isnull().sum()

# Drop any row that contains a Null value 
# Note that the size of the dataframe has been reduced by 7 elements
# Note that all will be used to drop rows that contains only Null values

employee_df.dropna(how = 'any', inplace = True)

employee_df

# Let's read a CSV file using Pandas as follows

employee_df = pd.read_csv('Human_Resources.csv')
employee_df

# We can also indicate which columns we want to drop NaN from

employee_df.dropna(how = 'any', inplace = True, subset = ['MonthlyIncome', 'MonthlyRate', 'PercentSalaryHike'])

employee_df

# Let's read a CSV file using Pandas as follows

employee_df = pd.read_csv('Human_Resources.csv')
employee_df

# Calculate the average monthly income
employee_df['MonthlyIncome'].mean()

# You can use Fillna to fill a given column with a certain value

employee_df['MonthlyIncome'].fillna(employee_df['MonthlyIncome'].mean(), inplace = True)

employee_df

employee_df.isnull().sum()

"""**MINI CHALLENGE #13:**
- **Calculate the median monthly rate. Use the calculated median values to fill out missing data. Confirm that the process is successful**
"""

employee_df = pd.read_csv('Human_Resources.csv')
employee_df

employee_df.isnull().sum()

employee_df['MonthlyRate'].median()

employee_df['MonthlyRate'].fillna(employee_df['MonthlyRate'].median(), inplace = True)

employee_df

employee_df.isnull().sum()

"""# 14. CHANGE DATATYPES"""

# Let's read a CSV file using Pandas as follows

employee_df = pd.read_csv('Human_Resources.csv')
employee_df

employee_df.info()

# Let's convert the hourly rate from int64 to float64

employee_df['HourlyRate'] = employee_df['HourlyRate'].astype('float')

employee_df.info()

# Since we have limited number of classes, we can use the categrory datatype
# check the memory usage with the info method to ensure that the size has been reduced

employee_df['PerformanceRating'] = employee_df['PerformanceRating'].astype('category')
employee_df['RelationshipSatisfaction'] = employee_df['RelationshipSatisfaction'].astype('category')

# Notice the reduction in size

employee_df.info()

"""**MINI CHALLENGE #14:**
- **Convert the BusinessTravel column to category format.** 
- **How many KBytes in memory have been saved?**
"""

employee_df = pd.read_csv('Human_Resources.csv')
employee_df

employee_df.info()

employee_df['BusinessTravel'] = employee_df['BusinessTravel'].astype('category')
employee_df.info()